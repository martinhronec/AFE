{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Advanced Financial Econometrics\n",
    "## PhD seminar reading group\n",
    "\n",
    "#### Winter Semester 2019/2020\n",
    "\n",
    "#### Seminar 3 (Oct 23 2019): Chapter 5 (5.6-5.11)\n",
    "\n",
    "by Lucie Kraicova\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Basics: 5.6 - 5.11\n",
    "\n",
    "* 5.6 Bayesian Statistics\n",
    "* 5.7 Supervised Learning Algorithms\n",
    "* 5.8 Unsupervised Learning Algorithms\n",
    "* 5.9 Stochastic Gradient Descent\n",
    "* 5.10 Building a Machine Learning Algorithm\n",
    "* 5.11 Challenges Motivating Deep Learning\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Bayesian Statistics\n",
    "\n",
    "**Frequentist statistics**: We estimate a single value of $\\mathbb{\\theta}$.\n",
    "\n",
    "Using this approach we assume that the true $\\theta$ is fixed, but unknown, while the dataset is considered random, therefore also the $\\hat{\\theta}$.\n",
    "\n",
    "**Bayesian statistics**: We consider all possible values of $\\theta$ when making a prediction.\n",
    "\n",
    "Here the dataset is not considered random, as it is directly observed. The true $\\theta$ is unknown, uncertain, thus treated as a random variable.\n",
    "\n",
    "Before we observe the data, we represent our knowledge of $\\theta$ using the **prior probability distribution** $p\\left(\\theta\\right)$ (e.g. assuming _a priori_ that parameters lie in a finite range with a uniform distribution).\n",
    "Then we observe data $\\{x^{(1)},x^{(2)},...x^{(m)}\\}$ and update our belief about $\\theta$ using **Bayes' rule** and get the **posterior density**:\n",
    "\n",
    "$$p\\left(\\theta|x^{(1)},x^{(2)},...x^{(m)}\\right)=\\frac{p\\left(x^{(1)},x^{(2)},...x^{(m)}|\\theta\\right)p\\left(\\theta\\right)}{p\\left(x^{(1)},x^{(2)},...x^{(m)}\\right)}$$\n",
    "\n",
    "When we extend our dataset by one sample, our predicted distribution over this new sample is:\n",
    "\n",
    "$$p\\left(x^{(m+1)}|x^{(1)},x^{(2)},...x^{(m)}\\right)=\\int{p\\left(x^{(m+1)}|\\theta\\right)p\\left(\\theta|x^{(1)},x^{(2)},...x^{(m)}\\right) d\\theta}$$\n",
    "\n",
    "After observing data, there is still uncertainty about the true parameter values and this uncertainty is incorporated directly into our predictions. This may protect against overfitting\n",
    "\n",
    "* typically generalize better when there is limited training data\n",
    "* high computational costs on large training datasets\n",
    "* human judgement in the _prior_ selection \n",
    "\n",
    "(Example p.137: Bayesian Linear Regression)\n",
    "\n",
    "**Maximum _A Posteriori_ (MAP) Estimation** provides us with a single esimate of $\\theta$ while allowing the influence by the _prior_.\n",
    "MAP chooses the point of maximal posterior probability (probability density in the continuous case).\n",
    "\n",
    "$\\theta_{\\text{MAP}}=\\underset{\\theta}{\\text{ argmax}}\\text{ p}\\left(\\theta|x\\right)=\\underset{\\theta}{\\text{argmax}}\\left[ \\text{ log p}\\left(x|\\theta\\right)+\\text{ log p}\\left(\\theta\\right) \\right]$\n",
    "\n",
    "The decomposition shows how the MAP relates to the ML estimate. First term: log-Likelihood term, second term: log-prior distribution.\n",
    "\n",
    "Using the prior information we can achieve lower variance at the cost of increased bias compared to ML estimate.\n",
    "Many regularization strategies can be interpreted as MAP approximation to Bayesian inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Supervised Learning Algorithms\n",
    "Learning algorithms that learn to associate some input and output given training data that include both the inputs $x$ and outputs $y$. \n",
    "\n",
    "In **Probabilistic supervised learning** we estimate $p(y|x)$.\n",
    "\n",
    "**Support vector machines (SVM)** are one of the most influential approaches to supervised learning. The model uses linear function $w^{T}x+b$ to predict the presence of positive and negative classes (when the function becomes positive/ negative for given example).\n",
    "\n",
    "**Kernel trick** is an innovation associated with, but not limited to SVM. It is based on the observation that many machine learning algorithms (e.g. SVM) can be written exclusively in terms of dot products between examples. \n",
    "\n",
    "$w^{T}x+b=b+\\sum_{i=1}^{m}{\\alpha_{i}x^{T}x^{(i)}}$\n",
    "\n",
    "* $\\alpha$ is vector of coefficients\n",
    "* $x^{(i)}$ is a training example\n",
    "\n",
    "Then x can be replaced by output of **feature function** $\\phi(x)$, dot product with a **kernel** $k\\left(x,x^{(i)}\\right)=\\phi(x)\\cdot\\phi(x^{(i)})$ and the prediction can be done using function:\n",
    "\n",
    "$f(x)=b+\\sum_{i}\\alpha_{i}k\\left(x,x^{(i)}\\right)$.\n",
    "* nonlinear in $x$, linear in $\\phi(x)$ and $\\alpha$\n",
    "* $\\phi(x)$ considered fixed, only alpha is estimated\n",
    "* equivalent to estimation of linear model on input data preprocessed by $\\phi(x)$\n",
    "* helps us to deal with models that are nonlinear in x using convex optimization techniques\n",
    "* cost of evaluating linear in number of training examples\n",
    "\n",
    "Most commonly used is the **Gaussian kernel** $k(u,v)=N\\left(u-v;0,\\sigma^{2}I\\right)$ known as **Radial basis function (RBF)** and is described as performing **Template matching**. Here, a training example $x$ associated with training label $y$ becomes a template for class $y$. When test point $x'$ is close to training point $x$, the RBF has a large response and thus gives a large weight to $y$ in the estimation. \n",
    "\n",
    "Category of algorithms that employ the Kernel trick is known as **Kernel machines** or **Kernel methods**\n",
    "\n",
    "**k-Nearest Neighbor Regression** \n",
    "* interesting case with infinite training set\n",
    "* problem when there are more features and just some of them are relevant for the output\n",
    "\n",
    "**Decision Tree** \n",
    "* input space is broken into regions and subregions and usually, each leaf node maps every point in its input region to the same output.\n",
    "\n",
    "### 5.8 Unsupervised Learning Algorithms\n",
    "Learning algorithms that work on training data that include only features $x$, but not the supervisory signal $y$. They either extract information from the data and/or transform these data in an 'optimal' way. This enables to represent data in a different way. \n",
    "Examples: density estimation, learning to draw samples from a distribution, denoising,finding a manifold that the data lies near, clustering data in groups of related examples\n",
    "\n",
    "* Lower dimensional representation: compress information\n",
    "\n",
    "* Sparse representation: input entries should be mostly zero without discarding too much information\n",
    "\n",
    "* Independent representation: disentangle sources of variation underlying the data\n",
    "\n",
    "\n",
    "**Principal Components Analysis**\n",
    "It provides a means of compressing and decorrelating data. It learns an orthogonal, linear transformation of the data that projects an input $x$ to a representation $z$\n",
    "\n",
    "**k-means Clustering**\n",
    "It divides the training set into k different clusters of examples that are near each other. Provides sparsity, as we can think about the clustering in terms of k-dimensional one-hot code vectors $h$ representing the inputs. If $x$ belongs to cluster $i$, then $h_{i}=1$, all its other entries are zero. \n",
    "\n",
    "The algorithm works by initializing k different centroids $\\{\\mu^{(1)},\\mu^{(2)}...,\\mu^{(k)}\\}$ to different values. Then, each training example is assigned to cluster $i$, where $i$ is the index of nearest centroid $\\mu^{(i)}$. Then, each centroid $\\mu^{(i)}$ is updated to the mean of all training examples in the cluster $i$ and then the algorithm returns to the previous step.\n",
    "\n",
    "* problem of performance masurement (example of red trucks, red cars, gray trucks, gray cars)\n",
    "* distributed representation might be preferred to one-hot representation, as it could have more than one classification attributes per class\n",
    "* having many attributes reduces the burden on the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.9 Stochastic Gradient Descent (SGD)\n",
    "Learning algorithm underlying 'nearly all deep learning'. It extends gradient descent algorithm from Chapter 4.\n",
    "Reduces computational costs in case of large training sets, when the cost function can be decomposed as 'per-example loss functions' summed over all training examples. E.g. the negative conditional Log-likelihood of training data:\n",
    "$$ J(\\theta)=\\mathbb{E}_{x,y\\sim\\hat{p}_{data}}L\\left(x,y,\\theta\\right)=\\frac{1}{m}\\sum_{i=1}^{m}{L\\left(x^{(i)},y^{(i)},\\theta\\right)} \\\\\n",
    "L\\left(x,y,\\theta\\right)=-\\text{log }p\\left(y|x;\\theta\\right)$$\n",
    "\n",
    "$L$ is the per-example loss function and the gradient requires computing:\n",
    "$$ \\nabla_{\\theta}J(\\theta)=\\frac{1}{m}\\sum_{i=1}^{m}{\\nabla_{\\theta}L\\left(x^{(i)},y^{(i)},\\theta\\right)}$$\n",
    "\n",
    "Computational cost is $O(m)$ and with large training data, time to take a single gradient step becomes prohibitively long.\n",
    "\n",
    "SGD takes the gradient as an expectation that can be approximately estimated using a small set of samples. On each step of the algorithm we can draw uniformly a subsample of all the training examples available $\\mathbb{B}=\\{x^{(1)},x^{(2)},...,x^{(m')}\\}$ and estimate the gradient using this subsample:\n",
    "\n",
    "$$ g=\\frac{1}{m'}\\nabla_{\\theta}\\sum_{i=1}^{m'}{L\\left(x^{(i)},y^{(i)},\\theta\\right)}$$\n",
    "\n",
    "The stochastic gradient descent algorithm follows the estimated gradient downhill:\n",
    "$\\theta\\leftarrow\\theta-\\epsilon g$ where $\\epsilon$ is the learning rate.\n",
    "\n",
    "### 5.10 Building a Machine Learning Algorithm\n",
    "Nearly all deep learning algorithms can be decomposed into 4 basic parts:\n",
    "* Dataset\n",
    "* Cost function\n",
    "* Optimization procedure\n",
    "* Model\n",
    "\n",
    "As we can choose and manage each of these parts mostly independently from the others, we can obtain a wide variety of algorithms.\n",
    "\n",
    "### 5.11 Challenges Motivating Deep Learning\n",
    "**The curse of dimensionality**\n",
    "\n",
    "**Local constancy and smoothness regularization**\n",
    "\n",
    "**Manifold Learning**\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
